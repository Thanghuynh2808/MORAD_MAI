# Retail Product Matching (RPM) - Refactored Version

This project has been refactored from the original `Retail-Product-Matching` repository to improve maintainability, modularity, and to integrate model conversion tools (ONNX).

## ğŸš€ Refactoring Task Summary
- **Logic Separation**: Transitioned processing functions from a monolithic approach to a Class-based model with `ProductMatcher`.
- **Modularization**: Decoupled source code into specialized modules: `models` (loading/extraction/matching), `utils` (processing/visualization/common).
- **LightGlue-ONNX Integration**: Merged source code from the `LightGlue-ONNX` repository into the `tools/` directory to support local feature model export and optimization.
- **Standardization**: Updated function naming, variables, and directory structure to follow modern Python package standards.
- **Entry Point Optimization**: Clearly separated the main execution application (`app/main.py`) from auxiliary scripts (`scripts/`).

## ğŸ“ Project Structure

```text
RPM_modified/
â”œâ”€â”€ app/                        # Main application entry points
â”‚   â””â”€â”€ main.py                 # Batch image processing script
â”œâ”€â”€ configs/                    # Configuration management (YAML/JSON)
â”œâ”€â”€ data/                       # Models weights and data
â”‚   â”œâ”€â”€ support_images/         # Template images for gallery building
â”‚   â”œâ”€â”€ test_images/            # Input images for testing
â”‚   â”œâ”€â”€ result_images/          # Output results after matching
â”‚   â”œâ”€â”€ weights/                # YOLO weights, SuperPoint/LightGlue (ONNX)
â”‚   â””â”€â”€ support_db.pt           # Built Feature Bank (Feature database)
â”œâ”€â”€ retail_matcher/             # CORE PACKAGE
â”‚   â”œâ”€â”€ models/                 # Deep Learning model wrappers
â”‚   â”‚   â”œâ”€â”€ loader.py           # Model loading logic (YOLO, DINO, ONNX)
â”‚   â”‚   â”œâ”€â”€ extraction.py       # Feature extraction (Global & Local)
â”‚   â”‚   â””â”€â”€ matching.py         # Matching logic (Matrix & Hybrid)
â”‚   â”œâ”€â”€ utils/                  # Helper utilities
â”‚   â”‚   â”œâ”€â”€ common.py           # Logging, image loading
â”‚   â”‚   â”œâ”€â”€ processing.py       # Preprocessing, CLAHE, normalization
â”‚   â”‚   â””â”€â”€ visualization.py    # Bounding box and label drawing
â”‚   â””â”€â”€ pipeline.py             # ProductMatcher class (Pipeline orchestrator)
â”œâ”€â”€ scripts/                    # Auxiliary scripts
â”‚   â”œâ”€â”€ build_gallery.py        # Build feature bank from support_images
â”‚   â””â”€â”€ test_api_client.py      # Client to test the FastAPI endpoint
â”œâ”€â”€ server/                     # API SERVER (FastAPI)
â”‚   â”œâ”€â”€ app.py                  # Main API entry point
â”‚   â””â”€â”€ schemas.py              # Pydantic data models
â”œâ”€â”€ tools/                      # Development and extension tools
â”‚   â””â”€â”€ lightglue_export/       # Tools to convert/quantize LightGlue to ONNX
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile                  # Containerization for deployment
â”œâ”€â”€ docker-compose.yml          # GPU-enabled orchestration
â”œâ”€â”€ run_server.sh               # Quick-start script for local API
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation & Usage

### 1. Environment Setup
Ensure you have installed the required libraries (GPU recommended):
```bash
pip install -r requirements.txt
```

### 2. Prepare Weights & Data
The project expects weights to be located in `data/weights/`:
- YOLO: `data/weights/yolo/best-obb.pt`
- ONNX: `data/weights/lightglue/superpoint_batch.onnx` & `lightglue_batch.onnx`

### 3. Build Feature Bank (Gallery)
Before running the matching process, you must extract features for the template products:
```bash
python3 scripts/build_gallery.py
```

### 4. Run Matching (Batch Mode)
Process images in the `test_images` folder and save results to disk:
```bash
python3 app/main.py
```

## ğŸŒ API Deployment (FastAPI)

The project includes a robust API server to serve predictions in real-time.

### Local Run
Use the convenience script to start the server:
```bash
chmod +x run_server.sh
./run_server.sh
```
The API will be available at `http://localhost:8000`. You can access the interactive documentation at `http://localhost:8000/docs`.

### Test the API
You can test the prediction endpoint using the provided client:
```bash
python3 scripts/test_api_client.py data/test_images/1.jpg
```

### Docker Deployment (Production)
To deploy with GPU support using Docker Compose:
```bash
docker-compose up -d --build
```
*Note: Requires `nvidia-container-toolkit` installed on the host.*

## ğŸ“ˆ Technical Improvements
- **ProductMatcher Class**: Holds the state of loaded models, making the pipeline flexible for use in different environments (e.g., APIs, Notebooks).
- **Visualization Decoupling**: Drawing logic is separated from matching logic, allowing easy UI/style changes without affecting the algorithm.
- **Path Management**: Uses `pathlib` throughout for cross-platform compatibility.
- **Hybrid Matching**: Optimized combination of DINOv3 (global) and LightGlue (local) for robust product identification.
